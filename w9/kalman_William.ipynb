{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c69ee5",
   "metadata": {},
   "source": [
    "# Imports/Setup\n",
    "\n",
    "The work shown here attempts to use a Kalman filter to predict the prices of assets found in this portfolio. [portfolio](https://docs.google.com/spreadsheets/d/1EZj5M7dXGy-48i0PydZQa5gpUOYCQHDFRBlp_rU1sdo/edit#gid=1736594093)\n",
    "\n",
    "[Helpful article...](https://medium.com/dataman-in-ai/kalman-filter-explained-4d65b47916bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e32634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "stock_choice = 'MSFT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5eeb4a",
   "metadata": {},
   "source": [
    "# Collect Close Data\n",
    "\n",
    "The cells below pulls in the relevant data for each of the assets in the portfolio, collecting a year's worth of close data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755f3166",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Portfolio/investments.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m investments \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../Portfolio/investments.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m investments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m investments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_investment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m investments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_investment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      3\u001b[0m investments\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/DATA_618/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DATA_618/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/DATA_618/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DATA_618/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/DATA_618/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Portfolio/investments.csv'"
     ]
    }
   ],
   "source": [
    "investments = pd.read_csv('../Portfolio/investments.csv')\n",
    "investments['weights'] = investments['initial_investment'] / investments['initial_investment'].sum()\n",
    "investments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112826f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_data = pd.DataFrame(pd.date_range(dt.date(2022, 10, 30), periods=500).tolist())\n",
    "close_data.columns = ['Date']\n",
    "\n",
    "for index, row in investments.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    tmp = yf.Ticker(ticker)\n",
    "    tmp = tmp.history(start=dt.date(2022, 10, 30), end=dt.date(2023, 10, 30))['Close'].reset_index()\n",
    "    tmp['Date'] = pd.to_datetime(tmp['Date'].dt.date)\n",
    "    tmp.columns = ['Date', ticker]\n",
    "\n",
    "    close_data = pd.merge(close_data, tmp, how='inner', on='Date')\n",
    "close_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c175d",
   "metadata": {},
   "source": [
    "# Kalman Filter - Simple Example\n",
    "\n",
    "The cells below create a simple Kalman filter that is used to estimate the closing prices of MFST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efddf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "\n",
    "\n",
    "kf_sample = close_data[['Date', stock_choice]]\n",
    "\n",
    "# Construct a Kalman filter. Since our state vector only has a single value (price)\n",
    "# we can use single values for all required matrices. The estimate and measurement\n",
    "# error distributions are assumed to have mean 0 and standard deviation = 1.\n",
    "\n",
    "kf = KalmanFilter(transition_matrices = [1],    # The value of transition matrix.\n",
    "                  observation_matrices = [1],   # The value of the obersation matrix.\n",
    "                  initial_state_mean = 0,       # Any initial value. It will converge to the true state value.\n",
    "                  initial_state_covariance = 1, # Sigma value for the normally distributed estimate error.\n",
    "                  observation_covariance=1,     # Sigma value for the normally distributed measurement error.\n",
    "                  transition_covariance=.01)    # Allows for small turbulence in transition matrix.\n",
    "\n",
    "# Get the Kalman estimates\n",
    "state_means, _ = kf.filter(kf_sample[stock_choice].values)\n",
    "\n",
    "# Add to dataframe\n",
    "kf_sample['KF_estimate'] = np.array(state_means)\n",
    "kf_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(kf_sample['Date'], kf_sample[stock_choice], label='Actual Stock Price')\n",
    "plt.plot(kf_sample['Date'], kf_sample['KF_estimate'], label='KF Estimate')\n",
    "plt.xlabel('Date', fontweight='bold')\n",
    "plt.ylabel('Price', fontweight='bold')\n",
    "#plt.title(f'{stock choice} KF Estimate', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ff979",
   "metadata": {},
   "source": [
    "As can be seen from the above plot, the Kalman very quickly adapts and does quite well in estimating MSFT's closing price. One of the primary differnces between the estimated and actual data is that the estimated data has a much smoother curve with less noise; this is one of the primary hallmarks of Kalman filter estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316629c",
   "metadata": {},
   "source": [
    "# Kalman Filter - Prediction Example\n",
    "\n",
    "The cells below create an instance of `dart`'s `KalmanForecaster`, which uses a Kalman filter to make future predicitons on a set of data. This is done twice in the cells below (one instance in which data imputation is used, the other not) to see how well the forecaster predicts the last 4 days worth MFST's stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a24c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_train = kf_sample[kf_sample['Date'] < dt.datetime(2023, 10, 24)]\n",
    "actual = kf_sample[kf_sample['Date'] >= dt.datetime(2023, 10, 24)][stock_choice].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try, filling in empty dates with mean stock price (required for the timeseries datatype\n",
    "# when frequency is listed as \"daily\")\n",
    "\n",
    "from darts.models import KalmanForecaster\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries, constant_timeseries\n",
    "from darts.timeseries import TimeSeries as ts\n",
    "\n",
    "fill_val = kf_sample[stock_choice].mean()\n",
    "\n",
    "kf_train = kf_train.set_index(['Date'])\n",
    "kf_train = ts.from_dataframe(kf_train, value_cols=[stock_choice],\n",
    "                             fillna_value=fill_val,freq='D',fill_missing_dates=True)\n",
    "#kf_train = ts.from_dataframe(kf_sample, value_cols=['GOOGL'])\n",
    "future_cov = datetime_attribute_timeseries(kf_train, 'day', add_length=4)\n",
    "\n",
    "model = KalmanForecaster(dim_x=1)\n",
    "model.fit(kf_train, future_covariates=future_cov)\n",
    "pred = model.predict(4, future_covariates=future_cov)\n",
    "preds = pred.values().reshape(-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de9fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second try, using unlabelled time series so data imputation is not necessary.\n",
    "# this is the better method\n",
    "\n",
    "kf_train = kf_sample[kf_sample['Date'] < dt.datetime(2023, 10, 24)]\n",
    "kf_train = ts.from_dataframe(kf_train, value_cols=[stock_choice])\n",
    "\n",
    "future_cov = constant_timeseries(value=1, start=0, end=kf_sample.shape[0], length=None, freq=None)\n",
    "\n",
    "model.fit(kf_train, future_covariates=future_cov)\n",
    "pred = model.predict(4, future_covariates=future_cov)\n",
    "preds = pred.values().reshape(-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09a80c",
   "metadata": {},
   "source": [
    "To check the success of the predictions, we can calculate their mean average percentage error (MAPE), which is a common statistic used to evaluate the performance of forecasting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(actual, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd36a5",
   "metadata": {},
   "source": [
    "We see from the above that for these four data points, the MAPE comes out to a little bit over 1%. For forecasting models, anything under 5% is considered to be highly accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9014f69",
   "metadata": {},
   "source": [
    "# Kalman Filter - Analysis\n",
    "\n",
    "The cell below creates a function to automate the process of running the Kalman forecaster on any of the portfolio assets for a user inputted number of predictions. Making predicitons over a larger timescale across multiple assets will give us a sense of the model's robustness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26988008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kalman_forecaster(close, stock, num_predictions):\n",
    "    \n",
    "    if stock not in close.columns.values:\n",
    "        return 'Ticker symbol not included in provided close dataset...'\n",
    "    \n",
    "    kf_sample = close[['Date', stock]]\n",
    "    \n",
    "    if num_predictions > close.shape[0]:\n",
    "        return 'Number of expected predictions exceeds the number of observations...'\n",
    "    \n",
    "    num_samples = kf_sample.shape[0] - num_predictions\n",
    "    kf_train = kf_sample.iloc[:num_samples]\n",
    "\n",
    "    actual = kf_sample.iloc[num_samples:][stock].values\n",
    "    dates = kf_sample.iloc[num_samples:]['Date'].values\n",
    "\n",
    "    kf_train = ts.from_dataframe(kf_train, value_cols=[stock])\n",
    "\n",
    "    future_cov = constant_timeseries(value=1, start=0, end=kf_sample.shape[0], length=None, freq=None)\n",
    "\n",
    "    model.fit(kf_train, future_covariates=future_cov)\n",
    "    pred = model.predict(num_predictions, future_covariates=future_cov)\n",
    "    preds = pred.values().reshape(-1)\n",
    "    mape = mean_absolute_percentage_error(actual, preds)\n",
    "    return (dates, actual, preds, mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d035a6",
   "metadata": {},
   "source": [
    "First, the cell below tests the function using the XOM stock price and makes predictions for the last 30 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = run_kalman_forecaster(close_data, 'XOM', 30)\n",
    "print(f'MAPE for Kalman Filter Forecaster using XOM stock over 30 days: {test[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ed6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(test[0], test[1], label='Actual Stock Price')\n",
    "plt.plot(test[0], test[2], label='Forecasted Stock Price')\n",
    "plt.text(dt.date(2023, 10, 15), 116.1, f'MAPE: {round(test[3], 2)}%')\n",
    "plt.xlabel('Date', fontweight='bold')\n",
    "plt.ylabel('XOM Stock Price', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc56657",
   "metadata": {},
   "source": [
    "We see from the above that the Kalman forecaster even performs quite well over a span of 30 days. The plot created below shows how the accuracy of the predictions decreases as the number of predicitons becomes larger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "mapes = []\n",
    "\n",
    "for i in range(2, 100):\n",
    "    kf_run = run_kalman_forecaster(close_data, 'MSFT', i)\n",
    "    mapes.append([i, kf_run[3]])\n",
    "    \n",
    "mapes = pd.DataFrame(mapes, columns=['Prediction Length', 'MAPE'])\n",
    "plt.plot(mapes['Prediction Length'], mapes.MAPE)\n",
    "plt.xlabel('Prediction Length (Days)', fontweight='bold')\n",
    "plt.ylabel('MAPE (%)', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57dc96a",
   "metadata": {},
   "source": [
    "As in clear in the plot above, the MAPE tends to rise as we increase the number of days forecasted by the Kalman filter. As a final exercise, the plot created in the cells below show the MAPE values for all assets included in the portfolio when predicting their price for the past 30 days: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "mapes = []\n",
    "\n",
    "for ticker in investments.ticker.values:\n",
    "    kf_run = run_kalman_forecaster(close_data, ticker, 30)\n",
    "    mapes.append([ticker, kf_run[3]])\n",
    "\n",
    "mapes = pd.DataFrame(mapes, columns=['ticker', 'mape'])\n",
    "mapes = mapes.sort_values(by='mape')\n",
    "\n",
    "plt.barh(mapes.ticker, mapes.mape)\n",
    "plt.title('MAPE Values for 30 Day Predictions', fontweight='bold')\n",
    "plt.xlabel('MAPE (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212864b6",
   "metadata": {},
   "source": [
    "While there are some higher MAPE values shown in the above plot, almost all of the assets exhibit MAPE values less than 10% (still considered to be quite accurate for forecasting models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ffcd1b",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "The results in the above prove that the Kalman Filter does remarkably well when making predictions on closing stock prices, espeically on short timescales. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
