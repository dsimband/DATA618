{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymc4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymc4\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01marviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01maz\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymc4'"
     ]
    }
   ],
   "source": [
    "import pymc4 as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use('arviz-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMC4 Made Simple for PyMC3 Users\n",
    "\n",
    "In this notebook, we will use a simple Bayesian estimation example to learn how to use the PyMC4 syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Data\n",
    "\n",
    "To keep things simple, we will use a simple example in which we generate 1,000 data points from a normal distribution with a pre-specified $\\mu$ and $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU = 8\n",
    "SIG = 2.2\n",
    "\n",
    "data = np.random.normal(loc=MU, scale=SIG, size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of our estimation task is to estimate the true value of $\\mu$ and $\\sigma$ from the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "PyMC models are defined as functions with a `@pm.model` decorator on top.\n",
    "\n",
    "To specify random variables as Python objects, we use the `yield` statement. This stems from PyMC4's API design, which uses coroutines underneath the hood. The technical reason is documented in the PyMC4 design guide; what's cool here is that it also serves as a \"visual hack\" that lets you very quickly identify all of your random variables in a model. \n",
    "\n",
    "We're going to define our model in the code cell below.\n",
    "\n",
    "As a prior for the $\\mu$, we will use a relatively flat Normal distribution, and for the $\\sigma$ prior, a relatively flat Exponential distribution.\n",
    "\n",
    "Unlike PyMC3's distributions, which used spelled Greek letters as arguments, in PyMC4, we use the standardized \"location\", \"scale\", \"rate\" and \"concentration\" paradigm used by TensorFlow Probability's distributions, as well as NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129;43m@pm\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmodel\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExponential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "@pm.model\n",
    "def model(data):\n",
    "    mu = yield pm.Normal(loc=0, scale=10, name=\"mu\")\n",
    "    sig = yield pm.Exponential(rate=0.1, name=\"sig\")\n",
    "    \n",
    "    like = yield pm.Normal(loc=mu, scale=sig, observed=data, name=\"like\")\n",
    "    \n",
    "    return like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from Posterior\n",
    "\n",
    "Sampling from posterior distributions is more or less the same as in PyMC3.\n",
    "\n",
    "We call on the model function, and then pass the result to `pm.sample`.\n",
    "\n",
    "Unlike PyMC3, `pm.sample(model)` now returns both the trace _and_ the computed sampling stats.\n",
    "\n",
    "Give it a moment to sample; as of the alpha version of PyMC4, the progress bar is unavailable because sampling is also delegated to TensorFlow probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_model = model(data)\n",
    "\n",
    "trace = pm.sample(model(data), num_samples=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace returned is an ArviZ's InferenceData object, which is the central data format for ArviZ. InferenceData itself is just a container that maintains references to one or more `xarray.Dataset`. You can check the InferenceData structure specification [here](https://arviz-devs.github.io/arviz/schema/schema.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Posterior Distributions\n",
    "\n",
    "Visualizations were completely delegated to `arviz` in PyMC3, and that is the same in PyMC4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace, var_names=\"model/mu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recovered the true $\\mu$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace, var_names=\"model/__log_sig\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take the exponent of the posterior distribution trace values, we will recover back approximately 2.2 for the $\\sigma$ as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior/Posterior Predictive Samples\n",
    "\n",
    "Doing prior and posterior predictive sampling is an important part of the modelling workflow. Just like in PyMC3, this functionality has been added to PyMC4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws_prior = pm.sample_prior_predictive(estimation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_kde(draws_prior.prior_predictive['model/like'], label='prior_predictive');\n",
    "ax = az.plot_kde(data, label='data', plot_kwargs={'color':'C1'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`draws_prior` Is also an InferenceData object as such is ordered into groups, in this case we have a single group `prior_predictive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drew 1,000 i.i.d. samples from the prior distributions for each of the random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws_prior.prior_predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let make predictions from the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws_posterior = pm.sample_posterior_predictive(estimation_model, trace, \n",
    "                                                 inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`draws_posterior` Is also an InferenceData object, with the group `posterior_predictive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have called `pm.sample_posterior_predictive` with the argument `inplace=True` to add the `posterior_predictive` group to `trace` instead of generating a new object.\n",
    "\n",
    "Let's see what we got from sampling from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws_posterior.posterior_predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 10 chains, 800 samples for each observation (1st and 2nd dim) and 1000 observations.\n",
    "\n",
    "To make this clearer, Luciano Paz (one of the PyMC developers) provided the following explanation:\n",
    "\n",
    "> The shape of the output for a posterior predictive samples is (n_chains, samples_per_chain) + shape_of_rv output\n",
    ">\n",
    "> The shape of the RV in posterior predictive sampling takes the shape of the supplied observed values into account. This is not like what prior predictive sampling does, where it only cares about the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InferenceData objects can be easily concatenated, so you can have all the relevant data in the same place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_trace = trace + draws_posterior + draws_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is handy for example when performing posterior predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_ppc(combined_trace);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
